{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import Keras and Packages**"
      ],
      "metadata": {
        "id": "it233c3y2J3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oytJPOiC18DX"
      },
      "outputs": [],
      "source": [
        "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
        "# If you run this notebook on a different environment, e.g. your desktop, you may need to uncomment and install certain libraries.\n",
        "\n",
        "# !pip install numpy==1.21.4\n",
        "# !pip install pandas==1.3.4\n",
        "# !pip install keras==2.1.6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "sA2LKNDQ2Qab"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* When working with convolutional neural networks in particular, we will need additional packages."
      ],
      "metadata": {
        "id": "seLnBmgk2wWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
        "# from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
        "# from keras.layers import Flatten # to flatten data for fully connected layers"
      ],
      "metadata": {
        "id": "9Wv8Case2xYZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D # to add convolutional layers\n",
        "from keras.layers import MaxPooling2D # to add pooling layers\n",
        "from keras.layers import Flatten # to flatten data for fully connected layers\n"
      ],
      "metadata": {
        "id": "StCDYzYA4L-o"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layer with One set of convolutional and pooling layers"
      ],
      "metadata": {
        "id": "UVnWoLTB2_2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # import data\n",
        "# from keras.datasets import mnist\n",
        "\n",
        "# # load data\n",
        "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# # reshape to be [samples][pixels][width][height]\n",
        "# X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "# X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "metadata": {
        "id": "fIeq6R2d4QNK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pfMZenZ84hh2",
        "outputId": "936d668e-3a03-4057-9608-d55dc5046873"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy, keras\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.1\n",
            "    Uninstalling numpy-2.1.1:\n",
            "      Successfully uninstalled numpy-2.1.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.1.6\n",
            "    Uninstalling Keras-2.1.6:\n",
            "      Successfully uninstalled Keras-2.1.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.19.0 requires pandas>=1.5.0, but you have pandas 1.3.4 which is incompatible.\n",
            "bigframes 1.19.0 requires pandas>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "cudf-cu12 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, but you have pandas 1.3.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.3.4 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.3.4 which is incompatible.\n",
            "statsmodels 0.14.3 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.4 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.5.0 numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              },
              "id": "f5a05f3a50dc4545a419017c6d6040c0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwxgmdqV4j1z",
        "outputId": "4c2f99cb-6488-439c-bfd8-faac458a9406"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's normalize the pixel values to be between 0 and 1"
      ],
      "metadata": {
        "id": "4uIayqBH4s4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data"
      ],
      "metadata": {
        "id": "NQvQz09B4tZ4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's convert the target variable into binary categories"
      ],
      "metadata": {
        "id": "qWERMAnp4xkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of categories"
      ],
      "metadata": {
        "id": "69Iwnj9340FO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers."
      ],
      "metadata": {
        "id": "f1vRw7DA45uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_model():\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "MR91hsHc48WT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's call the function to create the model, and then let's train it and evaluate it."
      ],
      "metadata": {
        "id": "0w35Mv7t5Fje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfoBjz0b5IS5",
        "outputId": "a79a6ab8-c3c7-4c7f-8e3d-48531d46a2d0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 25s - 83ms/step - accuracy: 0.9222 - loss: 0.2879 - val_accuracy: 0.9694 - val_loss: 0.0989\n",
            "Epoch 2/10\n",
            "300/300 - 41s - 136ms/step - accuracy: 0.9750 - loss: 0.0855 - val_accuracy: 0.9779 - val_loss: 0.0658\n",
            "Epoch 3/10\n",
            "300/300 - 39s - 132ms/step - accuracy: 0.9831 - loss: 0.0560 - val_accuracy: 0.9823 - val_loss: 0.0506\n",
            "Epoch 4/10\n",
            "300/300 - 40s - 134ms/step - accuracy: 0.9872 - loss: 0.0436 - val_accuracy: 0.9864 - val_loss: 0.0444\n",
            "Epoch 5/10\n",
            "300/300 - 42s - 142ms/step - accuracy: 0.9893 - loss: 0.0357 - val_accuracy: 0.9874 - val_loss: 0.0405\n",
            "Epoch 6/10\n",
            "300/300 - 41s - 137ms/step - accuracy: 0.9912 - loss: 0.0291 - val_accuracy: 0.9847 - val_loss: 0.0445\n",
            "Epoch 7/10\n",
            "300/300 - 41s - 136ms/step - accuracy: 0.9931 - loss: 0.0232 - val_accuracy: 0.9882 - val_loss: 0.0362\n",
            "Epoch 8/10\n",
            "300/300 - 41s - 136ms/step - accuracy: 0.9941 - loss: 0.0198 - val_accuracy: 0.9878 - val_loss: 0.0378\n",
            "Epoch 9/10\n",
            "300/300 - 40s - 132ms/step - accuracy: 0.9952 - loss: 0.0161 - val_accuracy: 0.9883 - val_loss: 0.0359\n",
            "Epoch 10/10\n",
            "300/300 - 25s - 85ms/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.9872 - val_loss: 0.0408\n",
            "Accuracy: 0.9872000217437744 \n",
            " Error: 1.2799978256225586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layer with two sets of convolutional and pooling layers"
      ],
      "metadata": {
        "id": "dZi6H0F35N8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each."
      ],
      "metadata": {
        "id": "t8mkamhQ5PbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_model():\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "oaC9mJ8S5TW_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it."
      ],
      "metadata": {
        "id": "ctvkZL4i7E2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5QUpkRX7F8t",
        "outputId": "42fd611a-34a3-4798-a39b-7152dbec8dec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 25s - 84ms/step - accuracy: 0.8748 - loss: 0.4637 - val_accuracy: 0.9625 - val_loss: 0.1316\n",
            "Epoch 2/10\n",
            "300/300 - 41s - 136ms/step - accuracy: 0.9658 - loss: 0.1148 - val_accuracy: 0.9723 - val_loss: 0.0883\n",
            "Epoch 3/10\n",
            "300/300 - 42s - 139ms/step - accuracy: 0.9752 - loss: 0.0834 - val_accuracy: 0.9803 - val_loss: 0.0619\n",
            "Epoch 4/10\n",
            "300/300 - 24s - 79ms/step - accuracy: 0.9799 - loss: 0.0673 - val_accuracy: 0.9807 - val_loss: 0.0583\n",
            "Epoch 5/10\n",
            "300/300 - 41s - 135ms/step - accuracy: 0.9825 - loss: 0.0583 - val_accuracy: 0.9832 - val_loss: 0.0531\n",
            "Epoch 6/10\n",
            "300/300 - 41s - 137ms/step - accuracy: 0.9847 - loss: 0.0500 - val_accuracy: 0.9839 - val_loss: 0.0486\n",
            "Epoch 7/10\n",
            "300/300 - 41s - 137ms/step - accuracy: 0.9865 - loss: 0.0438 - val_accuracy: 0.9862 - val_loss: 0.0441\n",
            "Epoch 8/10\n",
            "300/300 - 40s - 134ms/step - accuracy: 0.9879 - loss: 0.0399 - val_accuracy: 0.9856 - val_loss: 0.0428\n",
            "Epoch 9/10\n",
            "300/300 - 40s - 132ms/step - accuracy: 0.9886 - loss: 0.0363 - val_accuracy: 0.9865 - val_loss: 0.0406\n",
            "Epoch 10/10\n",
            "300/300 - 24s - 79ms/step - accuracy: 0.9897 - loss: 0.0330 - val_accuracy: 0.9881 - val_loss: 0.0361\n",
            "Accuracy: 0.988099992275238 \n",
            " Error: 1.1900007724761963\n"
          ]
        }
      ]
    }
  ]
}
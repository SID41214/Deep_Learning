{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c598bdf-46fe-4f6e-9b8f-abe957049355",
   "metadata": {},
   "source": [
    "# **Develop GANs Using Keras**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a03b82-3c9a-48a0-87d4-ba8ca97f7de1",
   "metadata": {},
   "source": [
    "Develop generative adversarial networks (GANs) using Keras. Learn to preprocess data, construct the generator and discriminator models, combine them to create the GAN, train the GAN, and evaluate its performance. GANs are powerful tools for generating synthetic data, and this lab provides a solid foundation for further exploration and experimentation with more advanced GAN architectures and applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a463c748-217f-48a6-949e-76d64c0f79ae",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "\n",
    "- Build, train, and evaluate GANs using Keras \n",
    "- Explore GAN architectures, data preprocessing, model training, and performance evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e89fff-ca41-46c0-b4c2-f9984918362a",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb02ec8-e748-4cbe-a748-eb53ecf8739f",
   "metadata": {},
   "source": [
    "## Step-by-step instructions \n",
    "\n",
    "### Step 1: Data preprocessing \n",
    "\n",
    "#### Objective: \n",
    "- Load and preprocess the MNIST dataset for training a GAN. \n",
    "\n",
    "#### Instructions: \n",
    "1. Load the MNIST dataset: \n",
    "   - Use Keras to load the MNIST dataset.\n",
    "   - Normalize the image pixel values to the range [-1, 1].\n",
    "\n",
    "2. Reshape the data:\n",
    "   - Expand the dimensions of the images to match the input shape required by the GAN (28×28×1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd4d7e-31d5-4f39-952a-04159a927a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow-cpu==2.16.2\n",
    "\n",
    "# Suppress warnings and set environment variables\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac29c7-2f1f-4083-8fef-a5eea4ec4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import warnings\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to the range [-1, 1]\n",
    "x_train = x_train.astype('float32') / 127.5 - 1.\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5572e5d-8c44-4839-b49c-1d8c663a5a89",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "This step prepares the MNIST dataset for training by normalizing the pixel values to the range [-1, 1] and reshaping the images to have a single color channel. Normalization helps in faster convergence during training, and reshaping is required because the input layer of our GAN expects a three-dimensional tensor. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d10be-d922-45ce-9d60-c942048a98e3",
   "metadata": {},
   "source": [
    "### Step 2: Building the generator model \n",
    "\n",
    "#### Objective: \n",
    "- Construct the generator model for the GAN using the Keras functional API. \n",
    "\n",
    "#### Instructions: \n",
    "1. Define the generator. \n",
    "   - Create a Sequential model. \n",
    "   - Add Dense, LeakyReLU, BatchNormalization, and Reshape layers to build the generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86995c16-fe42-497b-ba0b-8f93cb634efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape \n",
    "\n",
    "# Define the generator model \n",
    "def build_generator(): \n",
    "    model = Sequential() \n",
    "    model.add(Dense(256, input_dim=100)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(512)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(1024)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(28 * 28 * 1, activation='tanh')) \n",
    "    model.add(Reshape((28, 28, 1))) \n",
    "    return model \n",
    "\n",
    "# Build the generator \n",
    "generator = build_generator() \n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853c6c1-0bc5-479b-ab79-1a88e5fa82b0",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "This step involves building the generator model for the GAN. The generator takes a random noise vector as an input and generates a synthetic image. The model uses Dense, LeakyReLU, BatchNormalization, and Reshape layers to achieve this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e4f8f-22e7-41dc-aafc-94ebdf1f04bc",
   "metadata": {},
   "source": [
    "### Step 3: Building the discriminator model \n",
    "\n",
    "#### Objective: \n",
    "- Construct the discriminator model for the GAN using the Keras functional API. \n",
    "\n",
    "#### Instructions: \n",
    "1. Define the discriminator. \n",
    "   - Create a Sequential model. \n",
    "   - Add Flatten, Dense, and LeakyReLU layers to build the discriminator. \n",
    "\n",
    "2. Compile the discriminator. \n",
    "   - Compile the model using binary cross-entropy loss and the Adam optimizer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca409673-63de-4deb-ad6b-e6f6e338d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "\n",
    "# Define the discriminator model \n",
    "def build_discriminator(): \n",
    "    model = Sequential() \n",
    "    model.add(Flatten(input_shape=(28, 28, 1))) \n",
    "    model.add(Dense(512)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dense(256)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    return model \n",
    "\n",
    "# Build and compile the discriminator \n",
    "discriminator = build_discriminator() \n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8949a73-ba1e-4589-aeb4-05da0e55ee34",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "This exercise involves building the discriminator model for the GAN. The discriminator takes an image as an input and outputs a probability indicating whether the image is real or fake. The model uses Flatten, Dense, and LeakyReLU layers to achieve this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8259d434-a360-4f68-933b-59995e9a453e",
   "metadata": {},
   "source": [
    "### Step 4: Building the GAN Model \n",
    "\n",
    "#### Objective: \n",
    "- Combine the generator and discriminator to create the GAN model using the Keras functional API. \n",
    "\n",
    "#### Instructions: \n",
    "1. Define the GAN. \n",
    "   - Create an input layer for the noise vector. \n",
    "   - Pass the noise vector through the generator to produce a synthetic image. \n",
    "   - Pass the synthetic image through the discriminator to get the classification. \n",
    "   - Compile the GAN using binary cross-entropy loss and the Adam optimizer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dc4a1-4e67-45a0-a700-72a70cf193ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input \n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "# Create the GAN by stacking the generator and the discriminator \n",
    "def build_gan(generator, discriminator): \n",
    "    discriminator.trainable = False \n",
    "    gan_input = Input(shape=(100,)) \n",
    "    generated_image = generator(gan_input) \n",
    "    gan_output = discriminator(generated_image) \n",
    "    gan = Model(gan_input, gan_output) \n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam') \n",
    "    return gan \n",
    "\n",
    "# Build the GAN \n",
    "gan = build_gan(generator, discriminator) \n",
    "gan.summary()\n",
    "\n",
    "\n",
    "# Sync discriminator weights from trainable to non-trainable in GAN\n",
    "gan.layers[2].set_weights(discriminator.get_weights())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24fbae-bd10-497e-a5fb-01fa7577982a",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "This step involves combining the generator and discriminator models to create the GAN. The GAN takes a noise vector as an input, generates a synthetic image using the generator, and classifies the image using the discriminator. The discriminator is set to non-trainable when compiling the GAN to ensure that only the generator is updated during the adversarial training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7883860-4735-4b82-b252-41c54cd06b1e",
   "metadata": {},
   "source": [
    "### Step 5: Training the GAN \n",
    "\n",
    "#### Objective: \n",
    "- Train the GAN on the MNIST dataset. \n",
    "\n",
    "#### Instructions: \n",
    "1. Define training parameters. \n",
    "   - Set the batch size, number of epochs, and sample interval. \n",
    " \n",
    "2. Train the discriminator. \n",
    "   - Sample a batch of real images from the dataset. \n",
    "   - Generate a batch of synthetic images from the generator. \n",
    "   - Train the discriminator on both real and generated images. \n",
    " \n",
    "3. Train the generator. \n",
    "   - Generate a batch of noise vectors. \n",
    "   - Train the GAN to improve the generator’s ability to fool the discriminator. \n",
    " \n",
    "4. Print the progress: \n",
    "   - Print the discriminator and generator losses at regular intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a25cfc-d485-4588-9b0d-7b23224f7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the discriminator model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Flatten\n",
    "\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Build and recompile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfe28b-224a-4ea2-b5ae-2255a0d40163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters \n",
    "\n",
    "batch_size = 64 \n",
    "epochs = 200\n",
    "sample_interval = 10\n",
    "\n",
    "# Adversarial ground truths \n",
    "real = np.ones((batch_size, 1)) \n",
    "fake = np.zeros((batch_size, 1)) \n",
    "\n",
    "# Training loop \n",
    "for epoch in range(epochs): \n",
    "    # Train the discriminator \n",
    "    idx = np.random.randint(0, x_train.shape[0], batch_size) \n",
    "    real_images = x_train[idx] \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "    generated_images = generator.predict(noise) \n",
    "    d_loss_real = discriminator.train_on_batch(real_images, real) \n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, fake) \n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
    "\n",
    "    # Train the generator \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "    g_loss = gan.train_on_batch(noise, real) \n",
    "\n",
    "    # Print the progress \n",
    "    if epoch % sample_interval == 0: \n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}] [D accuracy: {100 * d_loss[1]}%] [G loss: {g_loss}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b56010-dad8-4d83-900d-7d487b810d1f",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "This step involves training the GAN on the MNIST dataset. The training loop alternates between training the discriminator and the generator. The discriminator is trained on batches of real and generated images, whereas the generator is trained to improve its ability to fool the discriminator. The progress is printed at regular intervals to monitor the training process. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0d583-bd4a-4444-8e05-0f30dae1ce93",
   "metadata": {},
   "source": [
    "### Step 6: Assessing the Quality of Generated Images \n",
    "\n",
    "### Objective: \n",
    "- Evaluate the performance of the trained GAN. \n",
    "\n",
    "### Evaluating the GAN\n",
    "\n",
    "After training the GAN, we need to assess the quality of the synthetic images generated by the generator. There are two main ways to evaluate the performance of GANs: qualitative assessment and quantitative assessment.\n",
    "\n",
    "### Qualitative Assessment: Visual Inspection\n",
    "\n",
    "Visual inspection is a straightforward method to assess the quality of images generated by a GAN. You can use the `sample_images` function provided in the lab to visualize a grid of generated images. During visual inspection, look for the following qualities:\n",
    "\n",
    "- **Clarity**: The images should be sharp and not blurry. Blurry images indicate that the generator is struggling to learn the patterns in the data.\n",
    "- **Coherence**: The generated images should have a coherent structure that resembles the original images in the dataset. For example, in the case of MNIST, the generated images should resemble handwritten digits with the correct number of strokes and shapes.\n",
    "- **Diversity**: There should be a variety of images generated by the GAN. If all images look similar, it might indicate that the generator is overfitting or has collapsed to a single mode.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "1. Run the `sample_images` function after training the GAN to display a grid of generated images.\n",
    "2. Inspect the images for clarity, coherence, and diversity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98448ce8-1e78-4f8b-8fc9-dae47e3d1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def sample_images(generator, epoch, num_images=25): \n",
    "    noise = np.random.normal(0, 1, (num_images, 100)) \n",
    "    generated_images = generator.predict(noise) \n",
    "    generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1] \n",
    "    fig, axs = plt.subplots(5, 5, figsize=(10, 10)) \n",
    "    count = 0 \n",
    "\n",
    "    for i in range(5): \n",
    "        for j in range(5): \n",
    "            axs[i, j].imshow(generated_images[count, :, :, 0], cmap='gray') \n",
    "            axs[i, j].axis('off') \n",
    "            count += 1 \n",
    "    plt.show() \n",
    "\n",
    "# Sample images at the end of training \n",
    "sample_images(generator, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef73a9b-2c4e-472d-8567-869df5ee4f8a",
   "metadata": {},
   "source": [
    "By using visual inspection, you can quickly identify any issues with the generated images. If you notice blurriness, lack of structure, or lack of diversity, consider adjusting the model architecture or training parameters.\n",
    "\n",
    "### 2. Quantitative Assessment: Metrics\n",
    "\n",
    "While visual inspection provides an intuitive understanding of the GAN’s performance, it can be subjective. To objectively evaluate GAN performance, you can use quantitative metrics such as:\n",
    "\n",
    "- **Inception Score (IS)**: This score measures both the quality and diversity of generated images by using a pre-trained classifier (such as Inception-v3) to predict the class of each image. A higher score indicates that the images are both high-quality and diverse. However, IS is not very effective for simple datasets like MNIST; it’s more suitable for complex datasets.\n",
    "\n",
    "- **Fréchet Inception Distance (FID)**: This metric calculates the distance between the distributions of generated images and real images. A lower FID score indicates that the generated images are more similar to real images. FID is commonly used and considered a reliable metric for evaluating GAN performance.\n",
    "\n",
    "- **Discriminator Accuracy**: During training, if the discriminator's accuracy is around 50%, it suggests that the generator is producing realistic images that are hard to distinguish from real ones. This metric is easy to implement and provides quick feedback on the training progress.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "You can use the provided code snippet to calculate the discriminator's accuracy on both real and fake images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560d64c-078c-4773-b6c5-8fa443fde9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the discriminator accuracy on real vs. fake images\n",
    "noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "# Evaluate the discriminator on real images\n",
    "real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)]\n",
    "d_loss_real = discriminator.evaluate(real_images, np.ones((batch_size, 1)), verbose=0)\n",
    "\n",
    "# Evaluate the discriminator on fake images\n",
    "d_loss_fake = discriminator.evaluate(generated_images, np.zeros((batch_size, 1)), verbose=0)\n",
    "\n",
    "print(f\"Discriminator Accuracy on Real Images: {d_loss_real[1] * 100:.2f}%\")\n",
    "print(f\"Discriminator Accuracy on Fake Images: {d_loss_fake[1] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff4c3f-fb75-4720-88f2-5d777034ae68",
   "metadata": {},
   "source": [
    "If the discriminator’s accuracy is around 50%, it implies the generator has learned to produce realistic images. Higher or lower accuracy may suggest that either the generator is not producing convincing images, or the discriminator is overfitting.\n",
    "\n",
    "### 3. Combining Qualitative and Quantitative Assessments\n",
    "\n",
    "For a comprehensive evaluation of the GAN:\n",
    "\n",
    "1. **Start with visual inspection** to get a quick sense of image quality. If the images look blurry or too similar, it might indicate problems with the training process.\n",
    "\n",
    "2. **Use quantitative metrics** like FID or discriminator accuracy to provide objective evidence of the GAN’s performance.\n",
    "\n",
    "3. **Monitor training progress** by visualizing the generator and discriminator losses over time. This helps in understanding if the GAN is suffering from instability or if one model is overpowering the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4055e0-3be2-44ae-818d-9e7553083eaf",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "By combining qualitative inspection and quantitative metrics, you can effectively assess the quality of images generated by GANs. This dual approach provides a more robust evaluation, ensuring that the generated data is not only visually plausible but also statistically similar to the real data. Experiment with different architectures, learning rates, and training parameters to improve the GAN’s performance further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc7c98-acf9-4840-b841-7be3708b60f1",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1: Modify the generator’s architecture \n",
    "\n",
    "#### Objective: \n",
    "- Experiment with adding more layers to the generator to understand how the depth of the network impacts the quality of generated images. \n",
    "\n",
    "#### Instructions: \n",
    "1. Add one more Dense layer with 2048 units to the generator model. \n",
    "2. Rebuild the generator and print the summary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae363a5-f90f-4eaa-b1e7-2ac0f5f4598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b3373-bb9b-4965-a906-9af20d742c1c",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Modify the generator model by adding an additional Dense layer \n",
    "\n",
    "def build_generator(): \n",
    "    model = Sequential() \n",
    "    model.add(Dense(256, input_dim=100)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(512)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(1024)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(2048))  # New layer added \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(28 * 28 * 1, activation='tanh')) \n",
    "    model.add(Reshape((28, 28, 1))) \n",
    "    return model \n",
    "\n",
    "# Rebuild the generator \n",
    "generator = build_generator() \n",
    "generator.summary() \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4e4cf-d5a0-41bc-8f25-6273b5cde0ac",
   "metadata": {},
   "source": [
    "### Exercise 2 - Adjust the discriminator’s learning rate \n",
    "\n",
    "#### Objective: \n",
    "- Explore how changing the learning rate of the discriminator’s optimizer affects training stability and model performance. \n",
    "\n",
    "#### Instructions: \n",
    "1. Change the learning rate of the Adam optimizer for the discriminator to 0.0002. \n",
    "2. Rebuild and compile the discriminator with the new learning rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf9268-98ea-438f-883f-86d0762349a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864d437-d10e-4a89-9d5d-06ff4ce15e91",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LeakyReLU\n",
    "\n",
    "def build_discriminator(): \n",
    "    model = Sequential() \n",
    "    model.add(Flatten(input_shape=(28, 28, 1))) \n",
    "    model.add(Dense(512)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dense(256)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    return model \n",
    "\n",
    "# Rebuild and compile the discriminator with a lower learning rate \n",
    "discriminator = build_discriminator() \n",
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                      optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), \n",
    "                      metrics=['accuracy']) \n",
    "\n",
    "discriminator.summary()\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768aacc-54b4-42c9-8dc8-bb366a8118e1",
   "metadata": {},
   "source": [
    "### Exercise 3 - Visualize training progress \n",
    "\n",
    "#### Objective: \n",
    "- Visualize the loss of the discriminator and generator during training to monitor the training process.  \n",
    "\n",
    "#### Instructions: \n",
    "1. Modify the training loop to store the discriminator and generator losses. \n",
    "2. Plot the losses after training to visualize the training progress. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689f083-eb4d-406f-93d5-1dbf03fbfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0efb42-f153-47cc-9293-9212c526f6af",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Initialize lists to store losses \n",
    "d_losses = [] \n",
    "g_losses = [] \n",
    "\n",
    " \n",
    "# Training loop with loss storage \n",
    "for epoch in range(epochs): \n",
    "    idx = np.random.randint(0, x_train.shape[0], batch_size) \n",
    "    real_images = x_train[idx] \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "    generated_images = generator.predict(noise) \n",
    "    d_loss_real = discriminator.train_on_batch(real_images, real) \n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, fake) \n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
    "    d_losses.append(d_loss[0]) \n",
    "  \n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "    g_loss = gan.train_on_batch(noise, real) \n",
    "    g_losses.append(g_loss) \n",
    "\n",
    "  \n",
    "    if epoch % sample_interval == 0: \n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}] [D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\") \n",
    "  \n",
    "# Plot the training losses \n",
    "plt.figure(figsize=(10, 5)) \n",
    "plt.plot(d_losses, label='Discriminator Loss') \n",
    "plt.plot(g_losses, label='Generator Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss') \n",
    "plt.title('Training Losses') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8da9ee-f40b-4227-aadf-e9bb9307673d",
   "metadata": {},
   "source": [
    "### Summary \n",
    "By completing these exercises: \n",
    "1. Understand the impact of adding more layers to the generator on the quality of generated images. \n",
    "2. Learn how adjusting the learning rate of the discriminator’s optimizer can affect training stability and performance. \n",
    "3. Visualize the training progress by plotting the losses of the discriminator and generator. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "99a1303fe664ec779e5ae71de5aca9f7cff990b2845f58fc9f5e6c11f14c8199"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
